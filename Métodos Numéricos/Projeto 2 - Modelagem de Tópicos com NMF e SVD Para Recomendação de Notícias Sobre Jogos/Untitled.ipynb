{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d50b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações de notícias com base no NMF:\n",
      "5906    I agree thouroughly!!  Screw the damn contract...\n",
      "295     \\n\\n\\nHow much do you watch and follow hockey?...\n",
      "258     -=> Quoting Bill Gregory to All <=-\\n\\n \\n\\n B...\n",
      "7037    Hey,guess what's coming to ESPN for a change? ...\n",
      "1403    If I were Pat Burns I'd throw in the towel. Th...\n",
      "Name: Text, dtype: object\n",
      "\n",
      "Recomendações de notícias com base no SVD:\n",
      "4698    \\n\\n\\n\\nThe top 11 teams of this tournament wi...\n",
      "454     \\n\\n\\n\\n\\n\\nHow is that possible?  He was on t...\n",
      "2871    Tuesday's game of Beloved Yakult Swallows\\n\\n(...\n",
      "6239    Who holds the record for most career strikeout...\n",
      "3996    \\nGee, they lost to St. Louis twice this year....\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "# Carregar o conjunto de dados \"fetch_20newsgroups\"\n",
    "newsgroups_data = fetch_20newsgroups(subset='test', remove=remove)\n",
    "\n",
    "# Criar um DataFrame a partir dos dados\n",
    "df = pd.DataFrame({'Text': newsgroups_data.data, 'Target': newsgroups_data.target})\n",
    "\n",
    "# Criar uma matriz TF-IDF dos documentos\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Aplicar a Factorização de Matrizes Não-Negativas (NMF)\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_matrix = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Aplicar a Decomposição em Valores Singulares (SVD)\n",
    "svd_model = TruncatedSVD(n_components=num_topics, random_state=42)\n",
    "svd_matrix = svd_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Calcular as similaridades entre os documentos\n",
    "nmf_similarities = cosine_similarity(nmf_matrix)\n",
    "svd_similarities = cosine_similarity(svd_matrix)\n",
    "\n",
    "# Função para recomendar artigos com base no interesse do usuário\n",
    "def recommend_articles(interest, num_recommendations=5):\n",
    "    # Vetorizar o interesse do usuário\n",
    "    interest_vec = vectorizer.transform([interest])\n",
    "\n",
    "    # Transformar o interesse usando NMF e SVD\n",
    "    interest_nmf = nmf_model.transform(interest_vec)\n",
    "    interest_svd = svd_model.transform(interest_vec)\n",
    "\n",
    "    # Calcular a similaridade de cosseno entre o interesse do usuário e os documentos\n",
    "    nmf_similarities = cosine_similarity(interest_nmf, nmf_matrix)\n",
    "    svd_similarities = cosine_similarity(interest_svd, svd_matrix)\n",
    "\n",
    "    # Obter os índices dos documentos mais similares\n",
    "    nmf_indices = nmf_similarities.argsort()[0][::-1]\n",
    "    svd_indices = svd_similarities.argsort()[0][::-1]\n",
    "\n",
    "    # Recomendar os artigos mais relevantes\n",
    "    nmf_recommendations = df.iloc[nmf_indices[:num_recommendations]]['Text']\n",
    "    svd_recommendations = df.iloc[svd_indices[:num_recommendations]]['Text']\n",
    "\n",
    "    return nmf_recommendations, svd_recommendations\n",
    "\n",
    "# Exemplo de recomendação de artigos\n",
    "interest = \"Sports\"\n",
    "nmf_recommended_articles, svd_recommended_articles = recommend_articles(interest)\n",
    "\n",
    "print(\"Recomendações de notícias com base no NMF:\")\n",
    "print(nmf_recommended_articles)\n",
    "print(\"\\nRecomendações de notícias com base no SVD:\")\n",
    "print(svd_recommended_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16611e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1ec47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6824c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba97903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4086c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b365b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49b032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ce4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d532ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c25cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
