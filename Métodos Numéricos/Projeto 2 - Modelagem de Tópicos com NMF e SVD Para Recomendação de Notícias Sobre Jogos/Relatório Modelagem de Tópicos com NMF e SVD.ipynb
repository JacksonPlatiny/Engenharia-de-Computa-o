{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__PROJETO DE ÁLGEBRA LINEAR COMPUTACIONAL: Modelagem de Tópicos com NMF e SVD.__</center>\n",
    "\n",
    "#### <center>__EQUIPE: Jackson Platiny__</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Modelagem de Tópicos é uma técnica amplamente utilizada para descobrir temas ou tópicos subjacentes em um conjunto de documentos não rotulados. Ela permite extrair informações relevantes e identificar os principais temas discutidos em um corpus de textos.\n",
    "\n",
    "O NMF (Non-Negative Matrix Factorization) é um algoritmo de fatorização de matrizes que desempenha um papel importante na Modelagem de Tópicos. Ele assume que os dados de entrada são não negativos e busca decompor uma matriz original em duas matrizes de menor dimensão, de forma que o produto dessas duas matrizes seja uma aproximação da matriz original. Essa decomposição resulta em fatores latentes que podem ser interpretados como tópicos ou temas. O NMF é especialmente útil para a Modelagem de Tópicos, pois os fatores latentes gerados são não negativos, o que facilita a interpretação dos resultados.\n",
    "\n",
    "Por outro lado, o SVD (Singular Value Decomposition) é outra técnica amplamente utilizada para redução de dimensionalidade e análise de dados. Ele também pode ser aplicado na Modelagem de Tópicos. O SVD busca decompor uma matriz original em três matrizes de menor dimensão: uma matriz de valores singulares, uma matriz de vetores singulares à esquerda e uma matriz de vetores singulares à direita. Ao selecionar um número reduzido de componentes principais, é possível capturar as informações mais relevantes e representativas dos dados originais. No contexto da Modelagem de Tópicos, o SVD permite reduzir a dimensionalidade dos documentos e identificar os principais tópicos de forma eficiente.\n",
    "\n",
    "Tanto o NMF quanto o SVD são algoritmos poderosos para a Modelagem de Tópicos, permitindo descobrir padrões, identificar temas relevantes e realizar recomendações com base em documentos. Ambas as técnicas têm a vantagem de gerar resultados interpretáveis, o que facilita a compreensão e a análise dos tópicos extraídos. É importante ressaltar que tanto o NMF quanto o SVD são técnicas não supervisionadas, ou seja, não requerem a existência de rótulos ou categorias pré-definidas. Eles operam apenas com os dados textuais e, por meio da decomposição de matrizes, conseguem identificar os tópicos subjacentes de forma automatizada.\n",
    "\n",
    "Em resumo, a Modelagem de Tópicos com NMF e SVD são abordagens poderosas para explorar e extrair informações relevantes de grandes volumes de texto. Elas permitem descobrir tópicos latentes, reduzir a dimensionalidade dos dados e fornecer insights valiosos para análise e recomendações. Essas técnicas são amplamente aplicadas em áreas como processamento de linguagem natural, análise de sentimentos, sistemas de recomendação e muitas outras que envolvem a análise de grandes quantidades de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema a ser tratado é o da Modelagem de Tópicos em conjuntos de documentos não rotulados. Nesse contexto, temos um conjunto de textos, como artigos de notícias, documentos acadêmicos, posts em redes sociais ou outros dados desse tipo. No contexto desse relatório, o objetivo é conseguir identificar os tópicos, temas, assuntos ou palavras mais discutidos nesses textos, sem a necessidade de ter um tema explicitamente definido (como por exemplo, esportes, política, tecnologia, economia, celebridades, música, etc) e a partir disso, sugerir ao usuário 5 recomendações de leitura de notícias dentro dos conjuntos de dados utilizados nesse projeto, relacionados ao tópico de interesse escolhido por ele.\n",
    "\n",
    "Algumas características encontradas nesse problema são:\n",
    "\n",
    "Dados não rotulados: Não temos categorias ou rótulos pré-definidos para os documentos. O objetivo é descobrir automaticamente os temas ou tópicos relevantes presentes nos textos;\n",
    "\n",
    "Grande volume de dados: Frequentemente, trabalhamos com grandes conjuntos de documentos, o que requer técnicas eficientes de processamento e análise para extrair insights relevantes;\n",
    "\n",
    "Representação textual: Os documentos são representados por meio de texto. A análise e a modelagem dos tópicos precisam levar em conta a estrutura e o conteúdo linguístico dos textos;\n",
    "\n",
    "Interpretabilidade: Uma característica importante é a capacidade de interpretar os tópicos descobertos. Os resultados devem ser apresentados de forma compreensível, permitindo a análise e a interpretação humana dos temas extraídos, entre outros.\n",
    "\n",
    "As possíveis aplicações associadas à Modelagem de Tópicos são diversas e abrangem diferentes áreas:\n",
    "\n",
    "Análise de sentimentos: A identificação de tópicos permite entender os temas discutidos em determinados contextos, como opiniões sobre produtos, marcas ou eventos. Isso pode ser útil para análises de sentimentos e percepções públicas;\n",
    "\n",
    "Recomendação de conteúdo: Com a identificação de tópicos, é possível recomendar conteúdo relevante aos usuários. Por exemplo, em sites de notícias, é possível sugerir artigos relacionados com base nos tópicos de interesse dos usuários;\n",
    "\n",
    "Descoberta de tendências: A Modelagem de Tópicos permite identificar tendências emergentes em tempo real, como novos assuntos que estão ganhando destaque na mídia ou na sociedade;\n",
    "\n",
    "Organização e categorização de documentos: Os tópicos extraídos podem ser usados para organizar e categorizar grandes volumes de documentos de forma automatizada, facilitando a recuperação de informações e a navegação em sistemas de gerenciamento de conteúdo;\n",
    "\n",
    "Pesquisa acadêmica: A identificação de tópicos pode auxiliar pesquisadores na análise e exploração de grandes conjuntos de artigos acadêmicos, facilitando a descoberta de trabalhos relacionados e avançando no conhecimento científico, entre outros.\n",
    "\n",
    "Em resumo, a Modelagem de Tópicos aborda o desafio de identificar automaticamente os principais temas em um conjunto de documentos não rotulados. As características do problema envolvem a análise de grandes volumes de dados textuais, a interpretabilidade dos resultados e a aplicação nas áreas acima mencionadas. Para os fins desse relatório, foram utilizadas as aplicações para recomendação de conteúdo, onde ao digitar um tema ou palavra de interesse do usuário em uma das funções, é possível encontrar alguns artigos no banco de dados que melhor se conectam com o tema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram utilizados dois métodos numéricos para solucionar o problema acima descrito, a Decomposição em Valores Singulares (SVD) e a Factorização de Matrizes Não-Negativas (NMF).\n",
    "\n",
    "A Decomposição em Valores Singulares é uma técnica de álgebra linear que permite decompor uma matriz em três componentes principais: matriz de valores singulares, matriz de vetores singulares esquerda e matriz de vetores singulares direita. No contexto da Modelagem de Tópicos, o SVD é aplicado na redução da dimensionalidade dos dados, preservando as informações mais relevantes.\n",
    "\n",
    "Como funciona:\n",
    "O SVD busca representar a matriz original como uma combinação linear dessas três componentes. Ele reorganiza as informações dos documentos e das palavras em um espaço de tópicos, onde cada documento é representado por uma combinação dos tópicos encontrados. O processo de redução da dimensionalidade permite capturar as relações mais importantes entre os documentos e as palavras, auxiliando na identificação dos tópicos.\n",
    "\n",
    "Por que é útil:\n",
    "O SVD é útil na Modelagem de Tópicos, pois permite reduzir a dimensionalidade dos dados, o que facilita a interpretação e a visualização dos tópicos extraídos. Além disso, o SVD é robusto e eficiente em lidar com grandes volumes de dados, tornando-se uma técnica valiosa para a análise de conjuntos de documentos extensos.\n",
    "\n",
    "A Factorização de Matrizes Não-Negativas é uma técnica que visa decompor uma matriz não-negativa em dois componentes não-negativos, geralmente interpretados como uma matriz de tópicos e uma matriz de distribuição de tópicos nos documentos. O NMF é uma abordagem popular na Modelagem de Tópicos, pois permite encontrar representações esparsas e interpretáveis dos documentos.\n",
    "\n",
    "Como funciona:\n",
    "O NMF procura aproximar a matriz original por meio de uma combinação linear de duas matrizes não-negativas. Essa combinação é obtida por meio de um processo iterativo que minimiza a diferença entre a matriz original e a sua reconstrução aproximada. Os tópicos são extraídos a partir da matriz de tópicos, enquanto a matriz de distribuição de tópicos nos documentos indica a relevância de cada tópico em cada documento.\n",
    "\n",
    "Por que é útil:\n",
    "O NMF é útil na Modelagem de Tópicos por sua capacidade de produzir representações esparsas e interpretáveis dos documentos. Isso significa que, para cada documento, apenas alguns tópicos são relevantes, facilitando a interpretação dos resultados. Além disso, o NMF também é eficaz em identificar tópicos subjacentes em um conjunto de documentos não rotulados.\n",
    "\n",
    "Em resumo, a utilização da Decomposição em Valores Singulares (SVD) e da Factorização de Matrizes Não-Negativas (NMF) nos códigos desenvolvidos para a Modelagem de Tópicos permite reduzir a dimensionalidade dos dados, capturar informações relevantes e identificar tópicos em conjuntos de documentos não rotulados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "4. IMPLEMENTAÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima foram importadas as bibliotecas e recursos necessários para utilização dos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados \"fetch_20newsgroups\"\n",
    "newsgroups_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "# Criar um DataFrame a partir dos dados\n",
    "dfreferencia = pd.DataFrame({'Text': newsgroups_data.data, 'Target': newsgroups_data.target})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima foi feito o carregamento do conjunto de dados da referência em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e criar o conjunto de dados da BBC News\n",
    "df = pd.read_csv('C:/Users/jacks/OneDrive/Área de Trabalho/metodos/BBC News Test.csv')  # Substitua pelo caminho correto do arquivo CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima foi feito o carregamento do conjunto de dados da BBC News em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Target\n",
      "0  I am a little confused on all of the models of...       7\n",
      "1  I'm not familiar at all with the format of the...       5\n",
      "2                                \\nIn a word, yes.\\n       0\n",
      "3  \\nThey were attacking the Iraqis to drive them...      17\n",
      "4  \\nI've just spent two solid months arguing tha...      19\n",
      "\n",
      "Index(['Text', 'Target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfreferencia.head())  # Exibe as primeiras linhas do DataFrame\n",
    "print()\n",
    "print(dfreferencia.columns)  # Exibe as colunas do DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima são exibidas as primeiras linhas do dataframe referência, bem como as colunas do mesmo, apenas para consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ArticleId                                               Text\n",
      "0       1018  qpr keeper day heads for preston queens park r...\n",
      "1       1319  software watching while you work software that...\n",
      "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
      "3        459  india s reliance family feud heats up the ongo...\n",
      "4       1020  boro suffer morrison injury blow middlesbrough...\n",
      "\n",
      "Index(['ArticleId', 'Text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head())  # Exibe as primeiras linhas do DataFrame\n",
    "print()\n",
    "print(df.columns)  # Exibe as colunas do DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima são exibidas as primeiras linhas do dataframe bbc, bem como as colunas do mesmo, apenas para consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Código para identificar tópicos em notícias e as palavras mais relevantes para o tópico utilizando os métodos NMF e SVD (Adaptação do presente na referência):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "vectorizer_ref = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix_ref = vectorizer_ref.fit_transform(dfreferencia['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é criada uma matriz TF-IDF dos documentos do conjunto referência usando o TfidfVectorizer do sklearn. Essa matriz representa a importância das palavras em cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é criada uma matriz TF-IDF dos documentos do conjunto bbc usando o TfidfVectorizer do sklearn. Essa matriz representa a importância das palavras em cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a modelagem de tópicos com NMF\n",
    "num_topics = 5\n",
    "nmf_model_ref = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_matrix_ref = nmf_model_ref.fit_transform(tfidf_matrix_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é aplicada a Factorização de Matrizes Não-Negativas (NMF) do conjunto referência usando a classe NMF do sklearn. O número de tópicos desejado é definido como 5. A matriz resultante do NMF é obtida utilizando o método fit_transform() aplicado à matriz TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a modelagem de tópicos com NMF\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_matrix = nmf_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é aplicada a Factorização de Matrizes Não-Negativas (NMF) do conjunto bbc usando a classe NMF do sklearn. O número de tópicos desejado é definido como 5. A matriz resultante do NMF é obtida utilizando o método fit_transform() aplicado à matriz TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as palavras mais importantes de cada tópico\n",
    "feature_names_ref = vectorizer_ref.get_feature_names_out()\n",
    "topic_words_ref = []\n",
    "for topic in nmf_model_ref.components_:\n",
    "    word_idx_ref = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words_ref.append([feature_names_ref[i] for i in word_idx_ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima são obtidas as palavras mais importantes de cada tópico do conjunto referência. Isso é feito percorrendo os componentes do modelo NMF e obtendo os índices das palavras mais relevantes para cada tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as palavras mais importantes de cada tópico\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "topic_words = []\n",
    "for topic in nmf_model.components_:\n",
    "    word_idx = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words.append([feature_names[i] for i in word_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima são obtidas as palavras mais importantes de cada tópico do conjunto bbc. Isso é feito percorrendo os componentes do modelo NMF e obtendo os índices das palavras mais relevantes para cada tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 1: people, don, just, think, like, know, right, time, government, good\n",
      "Tópico 2: windows, thanks, dos, file, program, know, does, files, use, help\n",
      "Tópico 3: game, games, espn, baseball, hockey, team, year, series, buffalo, fans\n",
      "Tópico 4: god, jesus, sin, christ, believe, bible, christian, faith, christians, love\n",
      "Tópico 5: drive, scsi, card, ide, disk, hard, monitor, controller, drives, 00\n"
     ]
    }
   ],
   "source": [
    "# Imprimir as palavras mais importantes de cada tópico\n",
    "for i, words in enumerate(topic_words_ref):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, os tópicos e suas palavras mais importantes do conjunto referência são impressos na saída. Cada tópico é identificado pelo número do tópico e suas palavras são exibidas em ordem de relevância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 1: game, england, rugby, win, play, wales, match, players, cup, team\n",
      "Tópico 2: mr, labour, blair, election, brown, party, howard, chancellor, government, tory\n",
      "Tópico 3: economy, growth, bank, year, prices, sales, economic, oil, 2004, china\n",
      "Tópico 4: people, music, mobile, technology, digital, users, broadband, games, phone, computer\n",
      "Tópico 5: film, best, award, awards, festival, oscar, prize, year, films, actress\n"
     ]
    }
   ],
   "source": [
    "# Imprimir as palavras mais importantes de cada tópico\n",
    "for i, words in enumerate(topic_words):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, os tópicos e suas palavras mais importantes do conjunto bbc são impressos na saída. Cada tópico é identificado pelo número do tópico e suas palavras são exibidas em ordem de relevância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a modelagem de tópicos com SVD\n",
    "svd_model_ref = TruncatedSVD(n_components=5, random_state=42)\n",
    "svd_topic_matrix_ref = svd_model_ref.fit_transform(tfidf_matrix_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é aplicada a Decomposição em Valores Singulares (SVD) do conjunto referência usando a classe TruncatedSVD do sklearn. O número de tópicos desejado é definido como 5. A matriz resultante do SVD é obtida utilizando o método fit_transform() aplicado à matriz TF-IDF (mesma ideia, mas agora com o SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a modelagem de tópicos com SVD\n",
    "svd_model = TruncatedSVD(n_components=5, random_state=42)\n",
    "svd_topic_matrix = svd_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é aplicada a Decomposição em Valores Singulares (SVD) do conjunto bbc usando a classe TruncatedSVD do sklearn. O número de tópicos desejado é definido como 5. A matriz resultante do SVD é obtida utilizando o método fit_transform() aplicado à matriz TF-IDF (mesma ideia, mas agora com o SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as palavras mais importantes de cada tópico\n",
    "topic_words_ref = []\n",
    "for topic in svd_model_ref.components_:\n",
    "    word_idx_ref = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words_ref.append([feature_names_ref[i] for i in word_idx_ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, são obtidas as palavras mais importantes de cada tópico do conjunto referência, percorrendo os componentes do modelo SVD e obtendo os índices das palavras mais relevantes para cada tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as palavras mais importantes de cada tópico\n",
    "topic_words = []\n",
    "for topic in svd_model.components_:\n",
    "    word_idx = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words.append([feature_names[i] for i in word_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, são obtidas as palavras mais importantes de cada tópico do conjunto bbc, percorrendo os componentes do modelo SVD e obtendo os índices das palavras mais relevantes para cada tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 1: don, like, just, know, people, think, does, time, use, god\n",
      "Tópico 2: windows, thanks, dos, drive, card, file, program, software, pc, disk\n",
      "Tópico 3: god, windows, jesus, sin, does, christ, dos, bible, believe, christian\n",
      "Tópico 4: god, game, games, windows, espn, baseball, hockey, jesus, dos, team\n",
      "Tópico 5: drive, scsi, god, ide, card, 00, controller, car, hard, sale\n"
     ]
    }
   ],
   "source": [
    "# Imprimir as palavras mais importantes de cada tópico\n",
    "for i, words in enumerate(topic_words_ref):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, os tópicos e suas palavras mais importantes do conjunto referência são impressos na saída. Cada tópico é identificado pelo número do tópico e suas palavras são exibidas em ordem de relevância, da mesma forma que no código anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 1: mr, people, year, labour, government, new, election, blair, brown, party\n",
      "Tópico 2: mr, labour, blair, election, brown, party, howard, chancellor, tory, government\n",
      "Tópico 3: economy, growth, sales, bank, prices, market, oil, company, china, economic\n",
      "Tópico 4: music, people, technology, mobile, digital, users, tv, film, phone, apple\n",
      "Tópico 5: film, award, best, awards, festival, oscar, films, prize, actress, aviator\n"
     ]
    }
   ],
   "source": [
    "# Imprimir as palavras mais importantes de cada tópico\n",
    "for i, words in enumerate(topic_words):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, os tópicos e suas palavras mais importantes do conjunto bbc são impressos na saída. Cada tópico é identificado pelo número do tópico e suas palavras são exibidas em ordem de relevância, da mesma forma que no código anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Código para recomendação de notícias com base em um interesse do usuário utilizando os métodos NMF e SVD (Desenvolvido nesse projeto).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "vectorizer_ref = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix_ref = vectorizer_ref.fit_transform(dfreferencia['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é criada uma matriz TF-IDF dos documentos do conjunto referência usando o TfidfVectorizer do sklearn, da mesma forma que nos códigos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima é criada uma matriz TF-IDF dos documentos do conjunto bbc usando o TfidfVectorizer do sklearn, da mesma forma que nos códigos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a modelagem de tópicos com NMF com um número maior de iterações\n",
    "num_topics = 10\n",
    "max_iter = 1000\n",
    "nmf_model_ref = NMF(n_components=num_topics, max_iter=max_iter, random_state=42)\n",
    "nmf_topics_ref = nmf_model_ref.fit_transform(tfidf_matrix_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima o NMF é aplicado à matriz TF-IDF do conjunto referência para obter as representações latentes dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a modelagem de tópicos com NMF com um número maior de iterações\n",
    "num_topics = 10\n",
    "max_iter = 1000\n",
    "nmf_model = NMF(n_components=num_topics, max_iter=max_iter, random_state=42)\n",
    "nmf_topics = nmf_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima o NMF é aplicado à matriz TF-IDF do conjunto bbc para obter as representações latentes dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir a dimensionalidade com SVD\n",
    "svd_model_ref = TruncatedSVD(n_components=100, random_state=42)\n",
    "svd_features_ref = svd_model_ref.fit_transform(tfidf_matrix_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima o SVD é aplicado à matriz TF-IDF do conjunto referência para obter as representações latentes dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir a dimensionalidade com SVD\n",
    "svd_model = TruncatedSVD(n_components=100, random_state=42)\n",
    "svd_features = svd_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima o SVD é aplicado à matriz TF-IDF do conjunto bbc para obter as representações latentes dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função desenvolvida nesse projeto para recomendar artigos com base no interesse do usuário\n",
    "def recommend_articles_ref(interest, num_recommendations=5):\n",
    "    # Vetorizar o interesse do usuário\n",
    "    interest_vec_ref = vectorizer_ref.transform([interest])\n",
    "\n",
    "    # Transformar o interesse usando NMF e SVD\n",
    "    interest_nmf_ref = nmf_model_ref.transform(interest_vec_ref)\n",
    "    interest_svd_ref = svd_model_ref.transform(interest_vec_ref)\n",
    "\n",
    "    # Calcular a similaridade de cosseno entre o interesse do usuário e os documentos\n",
    "    nmf_similarities_ref = cosine_similarity(interest_nmf_ref, nmf_topics_ref)\n",
    "    svd_similarities_ref = cosine_similarity(interest_svd_ref, svd_features_ref)\n",
    "\n",
    "    # Obter os índices dos documentos mais similares\n",
    "    nmf_indices_ref = nmf_similarities_ref.argsort()[0][::-1]\n",
    "    svd_indices_ref = svd_similarities_ref.argsort()[0][::-1]\n",
    "\n",
    "    # Recomendar os artigos mais relevantes\n",
    "    nmf_recommendations_ref = dfreferencia.iloc[nmf_indices_ref[:num_recommendations]]['Text']\n",
    "    svd_recommendations_ref = dfreferencia.iloc[svd_indices_ref[:num_recommendations]]['Text']\n",
    "\n",
    "    return nmf_recommendations_ref, svd_recommendations_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima a função recommend_articles é definida para recomendar artigos com base no interesse do usuário tendo como base o conjunto referência. Ela recebe um interesse como entrada e retorna as recomendações de artigos usando as similaridades do NMF e do SVD. As similaridades de cosseno entre o interesse do usuário e os documentos é calculada comparando as representações latentes com as matrizes do NMF e do SVD, logo depois os índices dos documentos mais similares são obtidos ordenando as similaridades, e em seguida por fim, os textos dos artigos mais relevantes são retornados com base nos índices obtidos utilizando o método NMF bem como utilizando o método SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função desenvolvida nesse projeto para recomendar artigos com base no interesse do usuário\n",
    "def recommend_articles(interest, num_recommendations=5):\n",
    "    # Vetorizar o interesse do usuário\n",
    "    interest_vec = vectorizer.transform([interest])\n",
    "\n",
    "    # Transformar o interesse usando NMF e SVD\n",
    "    interest_nmf = nmf_model.transform(interest_vec)\n",
    "    interest_svd = svd_model.transform(interest_vec)\n",
    "\n",
    "    # Calcular a similaridade de cosseno entre o interesse do usuário e os documentos\n",
    "    nmf_similarities = cosine_similarity(interest_nmf, nmf_topics)\n",
    "    svd_similarities = cosine_similarity(interest_svd, svd_features)\n",
    "\n",
    "    # Obter os índices dos documentos mais similares\n",
    "    nmf_indices = nmf_similarities.argsort()[0][::-1]\n",
    "    svd_indices = svd_similarities.argsort()[0][::-1]\n",
    "\n",
    "    # Recomendar os artigos mais relevantes\n",
    "    nmf_recommendations = df.iloc[nmf_indices[:num_recommendations]]['Text']\n",
    "    svd_recommendations = df.iloc[svd_indices[:num_recommendations]]['Text']\n",
    "\n",
    "    return nmf_recommendations, svd_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bloco acima a função recommend_articles é definida para recomendar artigos com base no interesse do usuário tendo como base o conjunto bbc. Ela recebe um interesse como entrada e retorna as recomendações de artigos usando as similaridades do NMF e do SVD. As similaridades de cosseno entre o interesse do usuário e os documentos é calculada comparando as representações latentes com as matrizes do NMF e do SVD, logo depois os índices dos documentos mais similares são obtidos ordenando as similaridades, e em seguida por fim, os textos dos artigos mais relevantes são retornados com base nos índices obtidos utilizando o método NMF bem como utilizando o método SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de recomendação de artigos\n",
    "interest = \"Sports\"\n",
    "nmf_recommended_articles_ref, svd_recommended_articles_ref = recommend_articles_ref(interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo de recomendação de textos de notícias é realizado com o interesse \"sports\" no conjunto referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de recomendação de artigos\n",
    "interest = \"Games\"\n",
    "nmf_recommended_articles, svd_recommended_articles = recommend_articles(interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo de recomendação de textos de notícias é realizado com o interesse \"games\" no conjunto bbc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações baseadas em NMF:\n",
      "6883    FULL 1993 CALDER CUP PLAYOFF SCHEDULE AND RESU...\n",
      "439     I forgot to mention that the stats are for gam...\n",
      "3840    NHL PLAYOFF RESULTS FOR GAMES PLAYED 23 APRIL ...\n",
      "1658    FULL 1993 CALDER CUP PLAYOFF SCHEDULE AND RESU...\n",
      "310     News:\\n=====\\nFor the first time all season, t...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Recomendações baseadas em NMF:\")\n",
    "print(nmf_recommended_articles_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recomendações do NMF para \"Sports\" no conjunto referência são impressas na saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações baseadas em NMF:\n",
      "689    sony psp console hits us in march us gamers wi...\n",
      "558    games  deserve a place in class  computer game...\n",
      "602    games enter the classroom video games could so...\n",
      "195    nintendo ds makes its euro debut nintendo s ds...\n",
      "56     ds aims to touch gamers the mobile gaming indu...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Recomendações baseadas em NMF:\")\n",
    "print(nmf_recommended_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recomendações do NMF para \"Games\" do conjunto bbc são impressas na saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recomendações baseadas em SVD:\n",
      "5814    I am curious to known if there are any profess...\n",
      "7305    I am curious to known if there are any profess...\n",
      "1576    \\n\\n\\nAnd unless I am mistaken (I screwed up m...\n",
      "7373    \\n\\nI believe he was well out of baseball by t...\n",
      "7501    \\nMy last car had T-Tops (BIG T-Tops).  My cur...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRecomendações baseadas em SVD:\")\n",
    "print(svd_recommended_articles_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recomendações do SVD para \"Sports\" no conjunto referência são impressas na saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recomendações baseadas em SVD:\n",
      "558    games  deserve a place in class  computer game...\n",
      "596    parents face video game lessons ways of ensuri...\n",
      "602    games enter the classroom video games could so...\n",
      "525    ea to take on film and tv giants video game gi...\n",
      "70     news corp eyes video games market news corp  t...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRecomendações baseadas em SVD:\")\n",
    "print(svd_recommended_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recomendações do SVD para \"Games\" no conjunto bbc são impressas na saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "5. CASOS DE USO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DATASET BBC News__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 1: NMF e SVD para identificar tópicos (ou temas, categorias) de notícias, assim como as palavras que mais são relevantes naquele tópico no conjunto BBC News."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando NMF:\n",
      "Tópico 1: game, england, rugby, win, play, wales, match, players, cup, team\n",
      "Tópico 2: mr, labour, blair, election, brown, party, howard, chancellor, government, tory\n",
      "Tópico 3: economy, growth, bank, year, prices, sales, economic, oil, 2004, china\n",
      "Tópico 4: people, music, mobile, technology, digital, users, broadband, games, phone, computer\n",
      "Tópico 5: film, best, award, awards, festival, oscar, prize, year, films, actress\n",
      "\n",
      "Utilizando SVD:\n",
      "Tópico 1: mr, people, year, labour, government, new, election, blair, brown, party\n",
      "Tópico 2: mr, labour, blair, election, brown, party, howard, chancellor, tory, government\n",
      "Tópico 3: economy, growth, sales, bank, prices, market, oil, company, china, economic\n",
      "Tópico 4: music, people, technology, mobile, digital, users, tv, film, phone, apple\n",
      "Tópico 5: film, award, best, awards, festival, oscar, films, prize, actress, aviator\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_matrix = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "topic_words = []\n",
    "for topic in nmf_model.components_:\n",
    "    word_idx = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words.append([feature_names[i] for i in word_idx])\n",
    "print(\"Utilizando NMF:\")\n",
    "for i, words in enumerate(topic_words):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=5, random_state=42)\n",
    "svd_topic_matrix = svd_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "topic_words = []\n",
    "for topic in svd_model.components_:\n",
    "    word_idx = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words.append([feature_names[i] for i in word_idx])\n",
    "print()\n",
    "print(\"Utilizando SVD:\")\n",
    "for i, words in enumerate(topic_words):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 2: Utilizando NMF e SVD para identificar notícias relacionadas a um assunto, tema ou tópico de interesse do usuário no conjunto BBC News."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações baseadas em NMF:\n",
      "689    sony psp console hits us in march us gamers wi...\n",
      "558    games  deserve a place in class  computer game...\n",
      "602    games enter the classroom video games could so...\n",
      "195    nintendo ds makes its euro debut nintendo s ds...\n",
      "56     ds aims to touch gamers the mobile gaming indu...\n",
      "Name: Text, dtype: object\n",
      "\n",
      "Recomendações baseadas em SVD:\n",
      "558    games  deserve a place in class  computer game...\n",
      "596    parents face video game lessons ways of ensuri...\n",
      "602    games enter the classroom video games could so...\n",
      "525    ea to take on film and tv giants video game gi...\n",
      "70     news corp eyes video games market news corp  t...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de recomendação de artigos\n",
    "#Função já ativada no tópico 4- Implementação\n",
    "print(\"Recomendações baseadas em NMF:\")\n",
    "print(nmf_recommended_articles)\n",
    "\n",
    "print(\"\\nRecomendações baseadas em SVD:\")\n",
    "print(svd_recommended_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo de recomendação de textos de notícias é realizado com o interesse \"Games\" no conjunto bbc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DATASET REFERÊNCIA__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 3: NMF e SVD para identificar tópicos (ou temas, categorias) de notícias, assim como as palavras que mais são relevantes naquele tópico no conjunto Referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando NMF:\n",
      "Tópico 1: people, don, just, think, like, know, right, time, government, good\n",
      "Tópico 2: windows, thanks, dos, file, program, know, does, files, use, help\n",
      "Tópico 3: game, games, espn, baseball, hockey, team, year, series, buffalo, fans\n",
      "Tópico 4: god, jesus, sin, christ, believe, bible, christian, faith, christians, love\n",
      "Tópico 5: drive, scsi, card, ide, disk, hard, monitor, controller, drives, 00\n",
      "\n",
      "Utilizando SVD:\n",
      "Tópico 1: don, like, just, know, people, think, does, time, use, god\n",
      "Tópico 2: windows, thanks, dos, drive, card, file, program, software, pc, disk\n",
      "Tópico 3: god, windows, jesus, sin, does, christ, dos, bible, believe, christian\n",
      "Tópico 4: god, game, games, windows, espn, baseball, hockey, jesus, dos, team\n",
      "Tópico 5: drive, scsi, god, ide, card, 00, controller, car, hard, sale\n"
     ]
    }
   ],
   "source": [
    "vectorizer_ref = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "tfidf_matrix_ref = vectorizer_ref.fit_transform(dfreferencia['Text'])\n",
    "\n",
    "num_topics = 5\n",
    "nmf_model_ref = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_matrix_ref = nmf_model_ref.fit_transform(tfidf_matrix_ref)\n",
    "\n",
    "feature_names_ref = vectorizer_ref.get_feature_names_out()\n",
    "\n",
    "topic_words_ref = []\n",
    "for topic in nmf_model_ref.components_:\n",
    "    word_idx_ref = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words_ref.append([feature_names_ref[i] for i in word_idx_ref])\n",
    "print(\"Utilizando NMF:\")\n",
    "for i, words in enumerate(topic_words_ref):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')\n",
    "\n",
    "svd_model_ref = TruncatedSVD(n_components=5, random_state=42)\n",
    "svd_topic_matrix_ref = svd_model_ref.fit_transform(tfidf_matrix_ref)\n",
    "\n",
    "topic_words_ref = []\n",
    "for topic in svd_model_ref.components_:\n",
    "    word_idx_ref = topic.argsort()[:-11:-1]  # Obter os índices das palavras mais importantes\n",
    "    topic_words_ref.append([feature_names_ref[i] for i in word_idx_ref])\n",
    "print()\n",
    "print(\"Utilizando SVD:\")\n",
    "for i, words in enumerate(topic_words_ref):\n",
    "    print(f'Tópico {i+1}: {\", \".join(words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 4: Utilizando NMF e SVD para identificar notícias relacionadas a um assunto, tema ou tópico de interesse do usuário no conjunto Referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações de notícias com base no NMF:\n",
      "6883    FULL 1993 CALDER CUP PLAYOFF SCHEDULE AND RESU...\n",
      "439     I forgot to mention that the stats are for gam...\n",
      "3840    NHL PLAYOFF RESULTS FOR GAMES PLAYED 23 APRIL ...\n",
      "1658    FULL 1993 CALDER CUP PLAYOFF SCHEDULE AND RESU...\n",
      "310     News:\\n=====\\nFor the first time all season, t...\n",
      "Name: Text, dtype: object\n",
      "\n",
      "Recomendações de notícias com base no SVD:\n",
      "5814    I am curious to known if there are any profess...\n",
      "7305    I am curious to known if there are any profess...\n",
      "1576    \\n\\n\\nAnd unless I am mistaken (I screwed up m...\n",
      "7373    \\n\\nI believe he was well out of baseball by t...\n",
      "7501    \\nMy last car had T-Tops (BIG T-Tops).  My cur...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de recomendação de artigos\n",
    "#Função já ativada no tópico 4- Implementação\n",
    "print(\"Recomendações de notícias com base no NMF:\")\n",
    "print(nmf_recommended_articles_ref)\n",
    "print(\"\\nRecomendações de notícias com base no SVD:\")\n",
    "print(svd_recommended_articles_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo de recomendação de textos de notícias é realizado com o interesse \"Sports\" no conjunto referência."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
